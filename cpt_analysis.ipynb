{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtthQja88EDlBTMh62/4wO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/david-c-brown/clinic_kpi_monthly/blob/main/cpt_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6zICntq3AOS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import csv\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"path/to/folder/\"\n",
        "\n",
        "# list of all clinics and their files\n",
        "\n",
        "clinics = glob.glob(file_path+'*') #glob glob glob\n",
        "\n",
        "# mapping names for consistency down the line\n",
        "clinic_mapping = {\n",
        "    'CLNC1': 'Clinic 1',\n",
        "    'CLINI2': 'Clinic 2',\n",
        "    'Clinic3': 'Clinic 3',\n",
        "    'Clinic_4': 'Clinic 4'\n",
        "}\n",
        "\n",
        "\n",
        "# marks when the analysis occurred, keeps runs organized\n",
        "now = datetime.now()\n",
        "month = now.strftime('%B').lower()\n",
        "year = now.strftime('%Y')\n",
        "filename = f'cpt_breakout_{month}_{year}.csv'\n",
        "\n",
        "# there is a finite amount of correct columns and infinite incorrect values\n",
        "columns = ['PT','All','97530','97535','97112','97110','97140','97001',\n",
        "           '97162','97163','97161','97002','97164','98960','97116','97033',\n",
        "           '97760','97150','97124','97039','97035','97032','97016','97014',\n",
        "           '97012','97010','95853','95852','95851','95597','G0283','G0282',\n",
        "           '20553','97608','92542','95992,29540','97610','64550','29240',\n",
        "           '29260','29280','29520','29530','29550','29200','29799','20552',\n",
        "           '97799','20053','97597','97750','97000','97774','97775','97776',\n",
        "           '97777','97546','NC001']"
      ],
      "metadata": {
        "id": "qC7dXdb03N6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_cpt(df):\n",
        "    # pt eval codes\n",
        "    eval_cols = ['97161', '97162', '97163']\n",
        "    # re-evaluation codes\n",
        "    reval = df[['97161', '97162', '97163', '97164']].sum()\n",
        "    if (reval > 0).any():\n",
        "        reval = np.nanmean(reval.loc['97164'] / reval[eval_cols])\n",
        "    else:\n",
        "        reval = 0.0\n",
        "\n",
        "    # num of eval codes verses # of codes\n",
        "    total_eval = df.loc[(df[eval_cols] == 1.0).any(axis=1) & (df['All'] <= 10)] # <=10 removes total rows, since we are using margins = True later on\n",
        "    if total_eval.shape[0] > 1:\n",
        "        total_eval = np.nansum(total_eval['All']) / np.nansum(total_eval[eval_cols])\n",
        "    else:\n",
        "        total_eval = 0.0\n",
        "\n",
        "    # num of codes per treatment block when not a new diagnosis\n",
        "    non_eval = df.loc[(df[eval_cols] == 0).all(axis=1)]\n",
        "    non_eval = non_eval['All'].sum() / non_eval.shape[0]\n",
        "\n",
        "    # high value billing code list\n",
        "    code_list = ['97530', '97535', '97112', '97001',\n",
        "                '97162', '97163', '97161', '97002',\n",
        "                '97164', '92542', '64550', '29280',\n",
        "                '29520', '29530', '29550', '29200',\n",
        "                '20552', '97799', '20053', '97750']\n",
        "\n",
        "    code_mix = df[code_list]\n",
        "    code_mix = (code_mix.sum().sum() / df['All'].sum()) # % of codes in the high value blend\n",
        "\n",
        "    try:\n",
        "        # write to csv for each provider\n",
        "        return writer.writerow([i,g, f'{code_mix:.0%}', f'{total_eval:.3}', f'{non_eval:.3}', f'{reval:.0%}'])\n",
        "    except:\n",
        "        # write to csv for each clinic\n",
        "        return writer.writerow([i,'Practice', f'{code_mix:.0%}', f'{total_eval:.3}', f'{non_eval:.3}', f'{reval:.0%}'])\n"
      ],
      "metadata": {
        "id": "SZ549XaW3rEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(filename, 'w', newline='') as file_object:\n",
        "    writer = csv.writer(file_object)\n",
        "    writer.writerow(['Clinic', 'PT','Code mix', 'Codes per eval', 'Codes per non eval', 'Re eval per Eval'])\n",
        "\n",
        "    for i in clinics:\n",
        "        df = pd.read_excel(i) # normally we would specify which file type, but files are inconsistently encoded\n",
        "\n",
        "        # cleaning payment processor naming conventions to map to our mapping dict we defined earlier\n",
        "        i = i.split('_', 1)[0]\n",
        "        i = i.rsplit('\\\\', 1)[-1]\n",
        "        try:\n",
        "            i = clinic_mapping[i] #changes name to actuals instead of external code\n",
        "        except:\n",
        "            pass\n",
        "        # cleaning up columns with extraneous information\n",
        "        df['CPT'] = df['CPT'].replace({'GP:':'', ':59':'', '.KX':''}, regex=True)\n",
        "        df['PT'] = df['PT'].replace({r'[A-Z]{2,3} \\(': '', r'[A-Z]{2} \\(': '', '\\)': ''}, regex=True)\n",
        "\n",
        "        # the groupby version of this is a fair bit messier, and about the same speed\n",
        "        pivot = np.round(pd.pivot_table(df, values= 'Units',\n",
        "                                    index=['PT','Patient','Date of Service'],\n",
        "                                    columns=['CPT'],\n",
        "                                    aggfunc='sum',\n",
        "                                    margins=True\n",
        "                                    ))\n",
        "\n",
        "        # moving our pivot into a more manageable form\n",
        "        clinic_df = pivot.reset_index().reindex(columns = columns).replace(np.nan, 0)\n",
        "        # this removes the total row while keeping the total column\n",
        "        clinic_df = clinic_df[clinic_df['PT'] != 'All']\n",
        "\n",
        "\n",
        "        # list of pts\n",
        "        pt = clinic_df.PT.unique()\n",
        "        analyze_cpt(clinic_df)\n",
        "\n",
        "        # loop through individual providers\n",
        "        for g in pt:\n",
        "            # make a df for each provider for individual analysis\n",
        "            pt_df = clinic_df.loc[(clinic_df['PT'].str.contains(g,regex =False))].copy()\n",
        "            pt_df.loc[:, 'PT'] = g\n",
        "            analyze_cpt(pt_df)\n",
        "            del g # removes PT from memory when cycling to the next clinic"
      ],
      "metadata": {
        "id": "PlafGqTm4AkG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}